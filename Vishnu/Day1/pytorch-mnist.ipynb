{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"pytorch-mnist.ipynb","provenance":[{"file_id":"https://github.com/rpi-techfundamentals/fall2018-materials/blob/master/10-deep-learning/04-pytorch-mnist.ipynb","timestamp":1627025350765}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ei4iuKxbRDLP"},"source":["This code is adopted from the pytorch examples repository. \n","It is licensed under BSD 3-Clause \"New\" or \"Revised\" License.\n","Source: https://github.com/pytorch/examples/\n","LICENSE: https://github.com/pytorch/examples/blob/master/LICENSE\n","\n","![](https://github.com/rpi-techfundamentals/fall2018-materials/blob/master/10-deep-learning/mnist-comparison.png?raw=1)\n","Table from [Wikipedia](https://en.wikipedia.org/wiki/MNIST_database)"]},{"cell_type":"code","metadata":{"id":"lp09CZ52RDLQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627029578767,"user_tz":-330,"elapsed":3345,"user":{"displayName":"Dr. SRI PHANI","photoUrl":"","userId":"17121511473050189039"}},"outputId":"c663cb2d-31d5-499f-d0fc-f1df3a1f2dfc"},"source":["!pip install torch torchvision"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JrCGqZmnRDLR","executionInfo":{"status":"ok","timestamp":1627029578768,"user_tz":-330,"elapsed":22,"user":{"displayName":"Dr. SRI PHANI","photoUrl":"","userId":"17121511473050189039"}}},"source":["#Import Libraries\n","\n","\n","from __future__ import print_function\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"we0SvAEmRDLR","executionInfo":{"status":"ok","timestamp":1627029578769,"user_tz":-330,"elapsed":21,"user":{"displayName":"Dr. SRI PHANI","photoUrl":"","userId":"17121511473050189039"}}},"source":["args={}\n","kwargs={}\n","args['batch_size']=1000\n","args['test_batch_size']=1000\n","args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n","args['lr']=0.01 #Learning rate is how fast it will decend. \n","args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n","\n","args['seed']=1 #random seed\n","args['log_interval']=10\n","args['cuda']=False\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"-K5xN7pmRDLS","executionInfo":{"status":"ok","timestamp":1627029578770,"user_tz":-330,"elapsed":21,"user":{"displayName":"Dr. SRI PHANI","photoUrl":"","userId":"17121511473050189039"}}},"source":["#load the data\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ])),\n","    batch_size=args['batch_size'], shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ])),\n","    batch_size=args['test_batch_size'], shuffle=True, **kwargs)\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7OXouWoRDLS","executionInfo":{"status":"ok","timestamp":1627029578771,"user_tz":-330,"elapsed":20,"user":{"displayName":"Dr. SRI PHANI","photoUrl":"","userId":"17121511473050189039"}}},"source":[""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sg7h5cExRDLS","executionInfo":{"status":"ok","timestamp":1627029578772,"user_tz":-330,"elapsed":19,"user":{"displayName":"Dr. SRI PHANI","photoUrl":"","userId":"17121511473050189039"}}},"source":["\n","\n","class Net(nn.Module):\n","    #This defines the structure of the NN.\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()  #Dropout\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        #Convolutional Layer/Pooling Layer/Activation\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n","        #Convolutional Layer/Dropout/Pooling Layer/Activation\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1, 320)\n","        #Fully Connected Layer/Activation\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        #Fully Connected Layer/Activation\n","        x = self.fc2(x)\n","        #Softmax gets probabilities. \n","        return F.log_softmax(x, dim=1)\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMGRGku2RDLT","executionInfo":{"status":"ok","timestamp":1627029578773,"user_tz":-330,"elapsed":19,"user":{"displayName":"Dr. SRI PHANI","photoUrl":"","userId":"17121511473050189039"}}},"source":["\n","def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        if args['cuda']:\n","            data, target = data.cuda(), target.cuda()\n","        #Variables in Pytorch are differenciable. \n","        data, target = Variable(data), Variable(target)\n","        #This will zero out the gradients for this batch. \n","        optimizer.zero_grad()\n","        output = model(data)\n","        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n","        loss = F.nll_loss(output, target)\n","        #dloss/dx for every Variable \n","        loss.backward()\n","        #to do a one-step update on our parameter.\n","        optimizer.step()\n","        #Print out the loss periodically. \n","        if batch_idx % args['log_interval'] == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.data))\n","\n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    for data, target in test_loader:\n","        if args['cuda']:\n","            data, target = data.cuda(), target.cuda()\n","        data, target = Variable(data, volatile=True), Variable(target)\n","        output = model(data)\n","        test_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n","        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n","        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"QERegSskRDLU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627029867449,"user_tz":-330,"elapsed":288693,"user":{"displayName":"Dr. SRI PHANI","photoUrl":"","userId":"17121511473050189039"}},"outputId":"8afb7346-7953-4589-a632-9f275530c51f"},"source":["model = Net()\n","if args['cuda']:\n","    model.cuda()\n","\n","optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n","\n","for epoch in range(1, args['epochs'] + 1):\n","    train(epoch)\n","    test()\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.354435\n","Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.316877\n","Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.291505\n","Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.271577\n","Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.250232\n","Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.211687\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 2.1210, Accuracy: 5129/10000 (51%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.172667\n","Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.112843\n","Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.015016\n","Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.945540\n","Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.814721\n","Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.711376\n","\n","Test set: Average loss: 1.2866, Accuracy: 7478/10000 (75%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.569851\n","Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.447878\n","Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.359041\n","Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.233549\n","Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.205129\n","Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.177015\n","\n","Test set: Average loss: 0.6894, Accuracy: 8304/10000 (83%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.122602\n","Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.036280\n","Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.964721\n","Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.963224\n","Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.935286\n","Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.854789\n","\n","Test set: Average loss: 0.4926, Accuracy: 8703/10000 (87%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.848641\n","Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.797309\n","Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.813962\n","Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.836979\n","Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.741387\n","Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.751295\n","\n","Test set: Average loss: 0.4045, Accuracy: 8918/10000 (89%)\n","\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.779247\n","Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.712415\n","Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.699767\n","Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.719899\n","Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.716929\n","Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.741627\n","\n","Test set: Average loss: 0.3456, Accuracy: 9060/10000 (91%)\n","\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.749103\n","Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.733864\n","Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.613126\n","Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.718993\n","Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.597848\n","Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.659772\n","\n","Test set: Average loss: 0.3105, Accuracy: 9129/10000 (91%)\n","\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.642109\n","Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.604725\n","Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.605130\n","Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.577820\n","Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.591690\n","Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.607355\n","\n","Test set: Average loss: 0.2805, Accuracy: 9212/10000 (92%)\n","\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.623384\n","Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.582906\n","Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.584954\n","Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.569781\n","Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.621173\n","Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.590170\n","\n","Test set: Average loss: 0.2619, Accuracy: 9249/10000 (92%)\n","\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.503592\n","Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.513594\n","Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.477983\n","Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.547219\n","Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.620753\n","Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.525349\n","\n","Test set: Average loss: 0.2434, Accuracy: 9300/10000 (93%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"soMeOYQfRDLU","executionInfo":{"status":"ok","timestamp":1627029867451,"user_tz":-330,"elapsed":8,"user":{"displayName":"Dr. SRI PHANI","photoUrl":"","userId":"17121511473050189039"}}},"source":[""],"execution_count":16,"outputs":[]}]}